{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs0YcTTMV+Gbeoqso0HVsa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jennifer-Kafui/climate-modeling/blob/main/Finite_Precision_Calculations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is to demonstrate that computer arithmetic is not the same as pure math / physically computed math because of finite precision (rounding and cutoff), Errors depends on the constant used and errors grows when repeated many times."
      ],
      "metadata": {
        "id": "jCOyBM0Ia8R3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBA3djAKWE3c",
        "outputId": "d073f437-8c0e-4d71-9fe0-311a2830b255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " sin ( pi /2):  1.0\n",
            " error :  0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np . set_printoptions(precision = 20) # Show lots of digits\n",
        "\n",
        "# example (a)\n",
        "sp = np.sin(np.pi / 2) # should be 1 .0000000000000000000000000000000000000\n",
        "error = sp - 1 # is it exactly zero?\n",
        "print (\" sin ( pi /2): \" , sp )\n",
        "print (\" error : \" , error )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example (b)\n",
        "err_gr = 0.0\n",
        "err_05 = 0.0\n",
        "err_08 = 0.0\n",
        "err_11 = 0.0\n",
        "err_20 = 0.0\n",
        "err_22 = 0.0\n",
        "err_32 = 0.0\n",
        "err_35 = 0.0\n",
        "gr = ( np . sqrt (5) - 1.0)/2.0\n",
        "\n",
        "for x in range (0 , 100000): # a \"for-loop\" in Python\n",
        "  #indent exactly 4 spaces untilthe ed of the loop\n",
        "  err_gr += abs(x - (1.0/ gr ) * x * gr )\n",
        "  err_05 += abs(x - (1.0/05.0) * x * 05.0)\n",
        "  err_08 += abs(x - (1.0/08.0) * x * 08.0)\n",
        "  err_11 += abs(x - (1.0/11.0) * x * 11.0)\n",
        "  err_20 += abs(x - (1.0/20.0) * x * 20.0)\n",
        "  err_22 += abs(x - (1.0/22.0) * x * 22.0)\n",
        "  err_32 += abs(x - (1.0/32.0) * x * 32.0)\n",
        "  err_35 += abs(x - (1.0/35.0) * x * 35.0)\n",
        "\n",
        "print (\" error (gr) : \" , err_gr )\n",
        "print (\" error (05) : \" , err_05 )\n",
        "print (\" error (08) : \" , err_08 )\n",
        "print (\" error (11) : \" , err_11 )\n",
        "print (\" error (20) : \" , err_20 )\n",
        "print (\" error (22) : \" , err_22 )\n",
        "print (\" error (32) : \" , err_32 )\n",
        "print (\" error (35) : \" , err_35 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQL2a6puc9W5",
        "outputId": "844a9a94-dc63-4099-c8f2-899ba12efa2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " error (gr) :  1.0034440034445424e-07\n",
            " error (05) :  1.3704605672515413e-07\n",
            " error (08) :  0.0\n",
            " error (11) :  7.896045595146006e-08\n",
            " error (20) :  1.3704605672515413e-07\n",
            " error (22) :  7.896045595146006e-08\n",
            " error (32) :  0.0\n",
            " error (35) :  1.4667781922383938e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 and 32 behave differently because they fit perfectly in binary, so calculations with them stay exact. Numbers like 5, 11, 20, 22, and 35 do not fit well in binary, so they get stored as approximations and cause small rounding errors that build up.\n",
        "\n",
        "When I changed the loop from 100,000 to 100, the errors became about 1000 times smaller, though not perfectly exact. I would say an error of 10⁻⁶ is negligible when it’s much smaller than the values I’m working with, like if my numbers are around 1."
      ],
      "metadata": {
        "id": "pnlClabBzD2H"
      }
    }
  ]
}